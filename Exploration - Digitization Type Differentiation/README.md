# Introduction

Exploration - Digitization Type Differentiation recognizes whether an image was digitized from Scanned or Microfilm material.

## Getting Started

These instructions will get you a copy of the project up and running on your local machine for development and testing purposes. See deployment for notes on how to deploy the project on a live system.

### Prerequisites

The required software and libraries are:
* Python 3.7
* MXNet 1.5
* CUDA 10.0 [if training on GPU]
* Matplotlib 3.1.1
* opencv-python 4.1
* numpy 1.17

### Installing

A step-by-step instruction on how to install required software systems and libraries.

1. Download Python 3.7 from <https://www.python.org/downloads/>
2. Download CUDA 10.0 from <https://developer.nvidia.com/cuda-toolkit-archive>
3. Install downloaded installation file
4. Open Terminal (for macOS), Command-Line (for Windows)
5. Install MXNet
```
pip install 'mxnet-cu100==1.5.1'
```
6. Install Matplotlib
```
python -m pip install -U 'matplotlib==3.1.1'
```
7. Install opencv-python
```
pip install 'opencv-python==4.1'
```
8. Install numpy
```
pip install 'numpy==1.17'
```

## Data Acquisition
For the first and second iteration:
The dataset was downloaded from the Library of Congress. To download the collectio, please refer to [the Civil War collection on By The People](https://crowd.loc.gov/topics/civil-war/). 

### Ground-truth
We sampled 1,200 images from the collection. Please refer text files for ground-truth:
1. micro-test.txt
2. micro-train.txt
3. scan-test.txt
4. scan-train.txt
Note: If more labels were needed, please refer to our [ground-truth construncting tool](https://git.unl.edu/unl_loc_summer_collab/codebase/tree/master/utils/GroudtruthBuilder).

## Running the training process

1. Configure the training
    1.1 set the path to save the training log
2. Download dataset from 
<https://git.unl.edu/unl_loc_summer_collab/labeled_data/tree/master/micrpfilm_scanning>
3. Copy the downloaded folder to the downloaded 'project5' folder
4. Run the training script
```
python train.py
```

### Formats of the training log

There are four files generated by the training process.
Training performance for each batch in the training set.
```
batch_stat_micro_affine_bak.txt
```
Testing performance for each batch in the testing set.
```
test_batch_stat_micro_affine_bak.txt
```
Each line of batch-specific log consists of ten parts split by "|".
They are:
1. the number ID of the batch;
2. the confusion table for the batch;
3. the number of the true positive for the batch;
4. the number of the true negative for the batch;
5. the number of the false positive for the batch;
6. the number of the false negative for the batch;
7. the average accuracy for the batch;
8. the average precision for the batch;
9. the average recall for the batch;
10. the average F1 score for the batch;

Training performance for each training step.
```
epoch_stat_micro_affine_bak.txt
```
Testing performance for each training step.
```
epoch_stat_test_micro_affine_bak.txt
```
Each line of training-step-specfic log consists of eleven parts split by "|".
They are:
1. the number ID of the training step;
2. the time elapsed for the training step;
3. the confusion table for the training step;
4. the number of the true positive for the training step;
5. the number of the true negative for the training step;
6. the number of the false positive for the training step;
7. the number of the false negative for the training step;
8. the average accuracy for the training step;
9. the average precision for the training step;
10. the average recall for the training step;
11. the average F1 score for the training step;

## Built With

* [Python](https://www.python.org/) - The programming language
* [CUDA Toolkit](https://developer.nvidia.com/cuda-toolkit) - Enable GPU for model training
* [MXNet](https://mxnet.apache.org/) - Deep learning framework

## Contributing

Digitization type differentiation using deep learning is promising
Enrich metadata tagging by recognizing digitization type automatically

## Authors

* **Yi Liu** - University of Nebraska-Lincoln - *email* - yil@cse.unl.edu